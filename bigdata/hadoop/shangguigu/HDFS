# 1. 概述

Hadoop Distributed File System, 分布式文件系统, 由NameNode, DataNode以及Secondary NameNode组成. NameNode存储文件的元数据, 如文件名, 文件目录结构, 文件属性以及每个文件的块列表和块所在的DataNode等. DataNode在本地文件系统存储文件块数据, 以及块数据的校验和. Secondary DataNode每隔一段时间对NameNode元数据备份.

# 2. 组成架构

* Secondary NameNode: 并非NameNode的热备, 当NN挂掉时不能马上替换NN并提供服务. 它的工作是辅助NN, 分担其工作量, 比如定期合并Fsimage和Edits, 并推送给NameNode. 在紧急情况下, 可辅助恢复NameNode.

# 3. 写数据流程

client向NN请求上传文件, NN检查元数据, 响应是否可以上传文件. 若可以上传, client向NN请求上传第一个Block(128M), NN返回用来存储数据的DN. client向DN请求建立Block传输通道, DN向client应答成功后, client向DN传输数据. 传输的数据为packet(64k), 而package是由(chunk512byte+chunksum4byte)组成. client存在ack机制, 在传输package时, 同时会缓存一份数据, 待收到传输数据确认信息后, 才会删除缓存.

# 4. 读数据流程

client向NN请求读文件, NN返回目标文件的元数据, client依据返回的元数据, 考虑负载均衡, 串行读取block.

# 5. NN和2NN工作机制

NN中的元数据若存储在磁盘中效率过低, 所以必须存储在内存中, 但是存储在内存中会存在数据丢失的风险. 因此产生了在磁盘中备份元数据的FsImage. 但是内存中元数据更新时, 由于HDFS追加比修改效率更高, 所以引入Edits文件, 只进行追加操作. FsImage和Edits合作, 可以合成元数据. 

# 6. DataNode工作机制

DN启动后向NN注册所有块信息, NN记录所有元数据, 并返回注册成功信息. DN每周期(6小时)上报所有块信息, DN每3s和NN建立心跳, 心跳返回结果带有NN给改DN的命令. NN在超过10分钟+30s没有收到DN的心跳, 则认为该节点不可用.